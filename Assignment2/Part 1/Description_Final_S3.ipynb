{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'F50A496718EDE4C8',\n",
       "  'HostId': 'mLiF3OkcOg/bhOE+r2KkGbQSIs4dL1Knw/R+AZIuY3DdJ5o3U16tzB04zE4M7Wz5HS7XtyRruaQ=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'mLiF3OkcOg/bhOE+r2KkGbQSIs4dL1Knw/R+AZIuY3DdJ5o3U16tzB04zE4M7Wz5HS7XtyRruaQ=',\n",
       "   'x-amz-request-id': 'F50A496718EDE4C8',\n",
       "   'date': 'Wed, 27 Feb 2019 09:41:22 GMT',\n",
       "   'etag': '\"011a7d905f17a210bb7ca2dcbfdfdd1f\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"011a7d905f17a210bb7ca2dcbfdfdd1f\"'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from xlwt import Workbook\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "contents = []\n",
    "bank_name= []\n",
    "job_url= []\n",
    "bigram_words= []\n",
    "bigram_final= []\n",
    "trigram_final= []\n",
    "\n",
    "#Opens the CSV file from Amazon S3 and appends the values according to the column\n",
    "client = boto3.client('s3',aws_access_key_id=aws_id, aws_secret_access_key=aws_secret)\n",
    "obj_job = client.get_object(Bucket='ads-assignment', Key='Job_Description.csv')\n",
    "df = pd.read_csv(obj_job['Body'])\n",
    "for i in df.columns:\n",
    "    i\n",
    "for ba in df['Bank Name']:\n",
    "     bank_name.append(ba)\n",
    "for ur in df['URL']:\n",
    "     job_url.append(ur)\n",
    "for de in df['Description']:\n",
    "    contents.append(de)\n",
    "    \n",
    "#Opens a new workbook\n",
    "wb = Workbook()\n",
    "add = wb.add_sheet('Final_Count', cell_overwrite_ok=True)\n",
    "row=1    \n",
    "col=3\n",
    "add.write(0,0, 'Bank Name')\n",
    "add.write(0,1, 'URL')\n",
    "add.write(0,2, 'Description')\n",
    "\n",
    "#Opens the word file from Amazon S3 and appends it to contents1\n",
    "contents1 = []\n",
    "\n",
    "client = boto3.client('s3',aws_access_key_id=aws_id, aws_secret_access_key=aws_secret)\n",
    "obj = client.get_object(Bucket='ads-assignment', Key='Final_Words.csv')\n",
    "df1 = pd.read_csv(obj['Body'])\n",
    "for wor in df1['Final Words']:\n",
    "    contents1.append(wor)\n",
    "    \n",
    "#Writes column names in the excel\n",
    "for i in contents1:\n",
    "    add.write(0,col,i)\n",
    "    col = col +1\n",
    "col_count=col\n",
    "\n",
    "col=3\n",
    "#Writes Bank names in the excel sheet at column 0\n",
    "for bankname in bank_name[:]:\n",
    "    bankname\n",
    "    add.write(row,0,bankname)\n",
    "    row = row +1    \n",
    "    \n",
    "row=1\n",
    "#Writes URL in the excel sheet at column 1\n",
    "for job_link in job_url[:]:\n",
    "    job_link\n",
    "    add.write(row,1,job_link)\n",
    "    row=row+1\n",
    "    \n",
    "row=1\n",
    "#Writes Job Desription in the excel sheet at column 2 and does the word count\n",
    "row1=1\n",
    "row2=1\n",
    "for jobdata in contents[:]:\n",
    "    word_tokens1 = word_tokenize(jobdata)\n",
    "    words1 = [w for w in word_tokens1 if w.isalpha()]\n",
    "    words_lowercase = [x.lower() for x in words1]\n",
    "\n",
    "#Converting the description to Bigrams and Trigrams\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    nltk_tokens = nltk.word_tokenize(jobdata)\n",
    "    words2 = [u for u in nltk_tokens if u.isalpha()]\n",
    "    words2_lowercase = [y.lower() for y in words2]\n",
    "    for z in words2_lowercase: \n",
    "        if z.lower() not in stop_words: \n",
    "            bigram_words.append(z)\n",
    "    bigram = list(nltk.bigrams(bigram_words))\n",
    "    trigram = list(nltk.trigrams(bigram_words))\n",
    "\n",
    "#Formatting both the bigrams and trigrams\n",
    "    for a in bigram:\n",
    "        b=a[0]+\" \"+a[1]\n",
    "        bigram_final.append(b)\n",
    "    for c in trigram:\n",
    "        d=c[0]+\" \"+c[1]+\" \"+c[2]\n",
    "        trigram_final.append(d)\n",
    "\n",
    "#Comparing the Unigram words in the description with the final fintech words\n",
    "    for num in contents1:\n",
    "        count = 0\n",
    "        for num1 in words_lowercase:\n",
    "            if num == num1:\n",
    "                count = count+1\n",
    "        add.write(row,2, jobdata)\n",
    "        add.write(row,col,count)\n",
    "            \n",
    "        col = col+1\n",
    "        if col == 105:\n",
    "            col = 3\n",
    "            row = row +1\n",
    "            break\n",
    "    \n",
    "    col1=105\n",
    "    \n",
    "#Comparing the Bigram words in the description with the final bigram fintech words\n",
    "    for num_bi in contents1[102:142]:\n",
    "        count_bi = 0\n",
    "        for num1_bi in bigram_final:\n",
    "            if num_bi == num1_bi:\n",
    "                count_bi = count_bi+1\n",
    "        add.write(row1,col1,count_bi)\n",
    "        col1 = col1+1\n",
    "        if col1 == 145:\n",
    "            col1 = 105\n",
    "            row1 = row1 +1\n",
    "    col2=145\n",
    "#Comparing the Trigram words in the description with the final Trigram fintech words\n",
    "    for num_tri in contents1[142:]:\n",
    "        count_tri = 0\n",
    "        for num1_tri in trigram_final:\n",
    "            if num_tri == num1_tri:\n",
    "                count_tri = count_tri+1\n",
    "        add.write(row2,col2,count_tri)\n",
    "        col2 = col2+1\n",
    "        if col2 == col_count:\n",
    "            col2 = 145\n",
    "            row2 = row2 +1\n",
    "    \n",
    "    del words_lowercase[:]\n",
    "    del bigram_final[:]\n",
    "    del bigram[:]\n",
    "    del bigram_words[:]\n",
    "    del trigram[:]\n",
    "    del trigram_final[:]\n",
    "\n",
    "wb.save(os.getcwd()+'/Part1.csv')\n",
    "\n",
    "s3 = boto3.resource('s3',aws_access_key_id=aws_id, aws_secret_access_key=aws_secret)\n",
    "bucket = s3.Bucket('ads-assignment')\n",
    "s3.Object('ads-assignment', 'Part1.csv').put(Body=open(os.getcwd()+'/Part1.csv', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
